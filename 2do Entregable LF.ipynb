{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPMQ/gu6aXZyQCFopJqNAWr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["import http.client\n","import json\n","import psycopg2\n","\n","# Configuración de la conexión y los encabezados\n","conn_api = http.client.HTTPSConnection(\"v2.nba.api-sports.io\")\n","headers = {\n","    'x-rapidapi-host': \"v2.nba.api-sports.io\",\n","    'x-rapidapi-key': \"3f41540dfbba32863f7981122084859b\"\n","}\n","\n","# Lista para almacenar los datos de los jugadores\n","players_data = []\n","\n","# Bucle para obtener datos de los jugadores con IDs del 1 al 10\n","for player_id in range(100, 102):\n","    # Crear y enviar la solicitud\n","    endpoint = f\"/players?id={player_id}\"\n","    conn_api.request(\"GET\", endpoint, headers=headers)\n","\n","    # Obtener la respuesta y decodificarla\n","    res = conn_api.getresponse()\n","    data = res.read()\n","    player_data = json.loads(data.decode(\"utf-8\"))\n","\n","    # Verificar la respuesta y agregar los datos del jugador a la lista\n","    if 'response' in player_data and player_data['response']:\n","        players_data.append(player_data['response'][0])\n","\n","# Datos de conexión a Redshift\n","host = \"data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com\"\n","dbname = \"data-engineer-database\"\n","user = \"lucasgfara_coderhouse\"\n","password = \"Bs1H2V5S4C\"\n","port = \"5439\"\n","\n","try:\n","    # Conexión a Redshift y creación de tabla\n","    conn_redshift = psycopg2.connect(\n","        host=host,\n","        dbname=dbname,\n","        user=user,\n","        password=password,\n","        port=port\n","    )\n","    cur = conn_redshift.cursor()\n","\n","    # Creación de la tabla en Redshift si no existe\n","    cur.execute(\"\"\"\n","        CREATE TABLE IF NOT EXISTS nba_players (\n","            id INT PRIMARY KEY,\n","            firstname VARCHAR(50),\n","            lastname VARCHAR(50),\n","            birth DATE,\n","            nba_start INT,\n","            nba_pro INT,\n","            height VARCHAR(10),\n","            weight VARCHAR(10),\n","            college VARCHAR(100),\n","            affiliation VARCHAR(100),\n","            leagues TEXT\n","        )\n","    \"\"\")\n","\n","    # Función para convertir datos de jugador en tupla\n","    def player_to_tuple(player):\n","      birth = player['birth']['date'] if player['birth']['date'] else None\n","      nba_start = player['nba']['start'] if player['nba']['start'] else None\n","      nba_pro = player['nba']['pro'] if player['nba']['pro'] else None\n","      leagues = json.dumps(player['leagues'])  # Convertir el diccionario de ligas a una cadena JSON\n","      return (\n","          player['id'], player['firstname'], player['lastname'], birth,\n","          nba_start, nba_pro, player['height']['inches'] if player['height'] else None,  # Asumiendo que 'height' tiene una clave 'inches'\n","          player['weight']['pounds'] if player['weight'] else None,  # Asumiendo que 'weight' tiene una clave 'pounds'\n","          player['college'], player['affiliation'], leagues\n","      )\n","\n","\n","    # Insertar datos obtenidos de la API en la tabla\n","    for player in players_data:\n","        player_tuple = player_to_tuple(player)\n","        cur.execute(\"\"\"\n","            INSERT INTO nba_players (id, firstname, lastname, birth, nba_start, nba_pro, height, weight, college, affiliation, leagues)\n","            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n","        \"\"\", player_tuple)\n","\n","    # Confirmar los cambios y cerrar la conexión\n","    conn_redshift.commit()\n","    print(\"Tabla creada y datos insertados en Redshift con éxito.\")\n","\n","except psycopg2.Error as e:\n","    print(\"Error al conectar a Redshift o al insertar datos:\", e)\n","\n","finally:\n","    if cur:\n","        cur.close()\n","    if conn_redshift:\n","        conn_redshift.close()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d-BuYYewaWgT","executionInfo":{"status":"ok","timestamp":1716258438039,"user_tz":180,"elapsed":2290,"user":{"displayName":"Lucas Fara","userId":"13441632176700300075"}},"outputId":"1b2dcd67-164c-4e3a-a575-3ac0e39358dd"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stdout","text":["Tabla creada y datos insertados en Redshift con éxito.\n"]}]},{"cell_type":"code","source":["import http.client\n","import json\n","import pandas as pd\n","import psycopg2\n","\n","# Configuración de la conexión y los encabezados\n","conn_api = http.client.HTTPSConnection(\"v2.nba.api-sports.io\")\n","headers = {\n","    'x-rapidapi-host': \"v2.nba.api-sports.io\",\n","    'x-rapidapi-key': \"3f41540dfbba32863f7981122084859b\"\n","}\n","\n","# Lista para almacenar los datos de los jugadores\n","players_data = []\n","\n","# Bucle para obtener datos de los jugadores con IDs del 1 al 100\n","for player_id in range(90, 100):\n","    # Crear y enviar la solicitud\n","    endpoint = f\"/players?id={player_id}\"\n","    conn_api.request(\"GET\", endpoint, headers=headers)\n","\n","    # Obtener la respuesta y decodificarla\n","    res = conn_api.getresponse()\n","    data = res.read()\n","    player_data = json.loads(data.decode(\"utf-8\"))\n","\n","    # Verificar la respuesta y agregar los datos del jugador a la lista\n","    if 'response' in player_data and player_data['response']:\n","        players_data.append(player_data['response'][0])\n","\n","# Crear DataFrame a partir de los datos de los jugadores\n","df = pd.DataFrame(players_data)\n","\n","# Eliminar filas con valores nulos en cualquier columna\n","df = df.dropna()\n","\n","# Renombrar las columnas college y affiliation\n","df = df.rename(columns={'college': 'university', 'affiliation': 'affiliate team'})\n","\n","# Eliminar filas duplicadas basadas en todas las columnas del DataFrame\n","df.drop_duplicates(inplace=True)\n","\n","# Concatenar firstname y lastname en una nueva columna 'full_name'\n","df['full_name'] = df['firstname'] + ' ' + df['lastname']\n","\n","# Datos de conexión a Redshift\n","host = \"data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com\"\n","dbname = \"data-engineer-database\"\n","user = \"lucasgfara_coderhouse\"\n","password = \"Bs1H2V5S4C\"\n","port = \"5439\"\n","\n","try:\n","    # Conexión a Redshift y creación de tabla\n","    conn_redshift = psycopg2.connect(\n","        host=host,\n","        dbname=dbname,\n","        user=user,\n","        password=password,\n","        port=port\n","    )\n","    cur = conn_redshift.cursor()\n","\n","    # Creación de la tabla en Redshift si no existe\n","    cur.execute(\"\"\"\n","        CREATE TABLE IF NOT EXISTS nba_players_new (\n","            id INT PRIMARY KEY,\n","            full_name VARCHAR(100),\n","            birth DATE,\n","            nba_start INT,\n","            nba_pro INT,\n","            height VARCHAR(10),\n","            weight VARCHAR(10),\n","            university VARCHAR(100),\n","            \"affiliate team\" VARCHAR(100),\n","            leagues TEXT\n","        )\n","    \"\"\")\n","\n","    # Insertar datos del DataFrame en la tabla de Redshift\n","    for index, row in df.iterrows():\n","        cur.execute(\"\"\"\n","            INSERT INTO nba_players_new (id, full_name, birth, nba_start, nba_pro, height, weight, university, \"affiliate team\", leagues)\n","            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n","        \"\"\", (row['id'], row['full_name'], row['birth'], row['nba_start'], row['nba_pro'], row['height'], row['weight'], row['university'], row['affiliate team'], json.dumps(row['leagues'])))\n","\n","    # Confirmar los cambios y cerrar la conexión\n","    conn_redshift.commit()\n","    print(\"Tabla creada y datos insertados en Redshift con éxito.\")\n","\n","except psycopg2.Error as e:\n","    print(\"Error al conectar a Redshift o al insertar datos:\", e)\n","\n","finally:\n","    if cur:\n","        cur.close()\n","    if conn_redshift:\n","        conn_redshift.close()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":478},"id":"Zw6KQJVxzVEn","executionInfo":{"status":"error","timestamp":1716255721920,"user_tz":180,"elapsed":885,"user":{"displayName":"Lucas Fara","userId":"13441632176700300075"}},"outputId":"c7d4b96c-349a-4912-e4dc-72a34ff364eb"},"execution_count":46,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"'firstname'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3653\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'firstname'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-7577e806dc06>\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Concatenar firstname y lastname en una nueva columna 'full_name'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'full_name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'firstname'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lastname'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# Datos de conexión a Redshift\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3761\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3763\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3654\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3655\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3656\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3657\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'firstname'"]}]},{"cell_type":"code","source":["import http.client\n","import json\n","import pandas as pd\n","import psycopg2\n","\n","# Configuración de la conexión y los encabezados\n","conn_api = http.client.HTTPSConnection(\"v2.nba.api-sports.io\")\n","headers = {\n","    'x-rapidapi-host': \"v2.nba.api-sports.io\",\n","    'x-rapidapi-key': \"3f41540dfbba32863f7981122084859b\"\n","}\n","\n","# Lista para almacenar los datos de los jugadores\n","players_data = []\n","\n","# Bucle para obtener datos de los jugadores con IDs del 1 al 100\n","for player_id in range(1, 3):\n","    # Crear y enviar la solicitud\n","    endpoint = f\"/players?id={player_id}\"\n","    conn_api.request(\"GET\", endpoint, headers=headers)\n","\n","    # Obtener la respuesta y decodificarla\n","    res = conn_api.getresponse()\n","    data = res.read()\n","    player_data = json.loads(data.decode(\"utf-8\"))\n","\n","    # Verificar la respuesta y agregar los datos del jugador a la lista\n","    if 'response' in player_data and player_data['response']:\n","        players_data.append(player_data['response'][0])\n","\n","\n","# Crear DataFrame a partir de los datos de los jugadores\n","df = pd.DataFrame(players_data)\n","print(df)\n","\n","# Eliminar filas con valores nulos en cualquier columna\n","df = df.dropna()\n","\n","# Renombrar las columnas college y affiliation\n","df = df.rename(columns={'college': 'university', 'affiliation': 'affiliate team'})\n","\n","# Eliminar filas duplicadas basadas en todas las columnas del DataFrame\n","df.drop_duplicates(inplace=True)\n","\n","# Concatenar firstname y lastname en una nueva columna 'full_name'\n","# df['full_name'] = df['firstname'] + ' ' + df['lastname']\n","\n","# Eliminar las columnas firstname y lastname del DataFrame\n","# df = df.drop(['firstname', 'lastname'], axis=1)\n","\n","# Datos de conexión a Redshift\n","host = \"data-engineer-cluster.cyhh5bfevlmn.us-east-1.redshift.amazonaws.com\"\n","dbname = \"data-engineer-database\"\n","user = \"lucasgfara_coderhouse\"\n","password = \"Bs1H2V5S4C\"\n","port = \"5439\"\n","\n","try:\n","    # Conexión a Redshift y creación de tabla\n","    conn_redshift = psycopg2.connect(\n","        host=host,\n","        dbname=dbname,\n","        user=user,\n","        password=password,\n","        port=port\n","    )\n","    cur = conn_redshift.cursor()\n","\n","    # Creación de la tabla en Redshift si no existe\n","    cur.execute(\"\"\"\n","        CREATE TABLE IF NOT EXISTS nba_players_new (\n","            id INT PRIMARY KEY,\n","            birth DATE,\n","            nba_start INT,\n","            nba_pro INT,\n","            height VARCHAR(10),\n","            weight VARCHAR(10),\n","            university VARCHAR(100),\n","            \"affiliate team\" VARCHAR(100),\n","            leagues TEXT,\n","            full_name VARCHAR(100)\n","        )\n","    \"\"\")\n","\n","    # Insertar datos del DataFrame en la tabla de Redshift\n","    for index, row in df.iterrows():\n","        cur.execute(\"\"\"\n","            INSERT INTO nba_players_new (id, birth, nba_start, nba_pro, height, weight, university, \"affiliate team\", leagues, full_name)\n","            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n","        \"\"\", (row['id'], row['birth'], row['nba_start'], row['nba_pro'], row['height'], row['weight'], row['university'], row['affiliate team'], json.dumps(row['leagues']), row['full_name']))\n","\n","    # Confirmar los cambios y cerrar la conexión\n","    conn_redshift.commit()\n","    print(\"Tabla creada y datos insertados en Redshift con éxito.\")\n","\n","except psycopg2.Error as e:\n","    print(\"Error al conectar a Redshift o al insertar datos:\", e)\n","\n","finally:\n","    if cur:\n","        cur.close()\n","    if conn_redshift:\n","        conn_redshift.close()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cyUBFc930ZDH","executionInfo":{"status":"ok","timestamp":1716258727593,"user_tz":180,"elapsed":1632,"user":{"displayName":"Lucas Fara","userId":"13441632176700300075"}},"outputId":"9aba2304-9172-46b7-8b9f-3f39b9e6124e"},"execution_count":59,"outputs":[{"output_type":"stream","name":"stdout","text":["Empty DataFrame\n","Columns: []\n","Index: []\n","Tabla creada y datos insertados en Redshift con éxito.\n"]}]}]}